<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.loli.net/css?family=Menlo:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"litianyang0211.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="article">
<meta property="og:title" content="Causal Inference">
<meta property="og:url" content="https://litianyang0211.github.io/Statistics/Graphical_Model/Causal_Inference">
<meta property="og:site_name" content="Tianyang Li">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://litianyang0211.github.io/images/Causal_Inference_1.png">
<meta property="article:published_time" content="2021-12-22T00:00:00.000Z">
<meta property="article:modified_time" content="2021-12-23T17:24:45.684Z">
<meta property="article:author" content="Tianyang Li">
<meta property="article:tag" content="Causal Inference">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://litianyang0211.github.io/images/Causal_Inference_1.png">

<link rel="canonical" href="https://litianyang0211.github.io/Statistics/Graphical_Model/Causal_Inference.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Causal Inference | Tianyang Li</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Tianyang Li</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-posts">

    <a href="/posts/" rel="section"><i class="fa fa-blog fa-fw"></i>Posts</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-projects">

    <a href="/projects/" rel="section"><i class="fa fa-code fa-fw"></i>Projects</a>

  </li>
        <li class="menu-item menu-item-friends">

    <a href="/friends/" rel="section"><i class="fa fa-user-friends fa-fw"></i>Friends</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://litianyang0211.github.io/Statistics/Graphical_Model/Causal_Inference">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Tianyang Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Tianyang Li">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Causal Inference
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-lightbulb"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-12-22 00:00:00" itemprop="dateCreated datePublished" datetime="2021-12-22T00:00:00+00:00">2021-12-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-edit"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-12-23 17:24:45" itemprop="dateModified" datetime="2021-12-23T17:24:45+00:00">2021-12-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a class=n href="/categories/Statistics/" itemprop="url" rel="index"><span itemprop="name">Statistics</span></a>
                </span>
                  /
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a class=n href="/categories/Statistics/Graphical-Model/" itemprop="url" rel="index"><span itemprop="name">Graphical Model</span></a>
                </span>
            </span>

          
            <div class="post-description"><div></div></div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="causal-inference">1. Causal Inference</h1>
<p><strong>Definition 1.1</strong>    Let <span class="math inline">\(\mathcal{G}\)</span> be a DAG, and <span class="math inline">\(p\)</span> be a distribution Markov w.r.t. <span class="math inline">\(\mathcal{G}\)</span>. <span class="math inline">\((\mathcal{G}, p)\)</span> is <strong>causal</strong> for <span class="math inline">\(X_V\)</span>, if <span class="math display">\[p(x_{V-A} \mid \text{do}(x_A))=\prod_{i \in V-A} p(x_i \mid x_{\text{pa}(i)})\]</span> for all <span class="math inline">\(A \subseteq V\)</span> and <span class="math inline">\(x_V \in \mathcal{X}_V\)</span>.</p>
<p><strong>Example 1.1</strong>    Suppose <span class="math inline">\(p\)</span> is causal w.r.t. <span class="math inline">\(\mathcal{G}\)</span>, then <span class="math inline">\(p(y, z \mid \text{do}(x))=p(z)p(y \mid x, z)\)</span>.</p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            Z((Z)) --> X((X)) & Y((Y))
X --> Y
          </pre>
<div class="note warning">
            <p><span class="math inline">\(p(y, z \mid \text{do}(x))=p(z)p(y \mid x, z) \neq p(y, z \mid x)\)</span>, where <span class="math inline">\(p(y, z \mid x)=p(z \mid x)p(y \mid x, z)\)</span>.</p><p>However, we still have <span class="math display">\[p(y \mid \text{do}(x))=\sum_z p(y, z \mid \text{do}(x))=\sum_z p(z)p(y \mid x, z)\]</span> or <span class="math display">\[p(z \mid \text{do}(x))=\sum_y p(y, z \mid \text{do}(x))=p(z)\sum_y p(y \mid x, z)=p(z).\]</span></p>
          </div>
<h1 id="causal-dag">2. Causal DAG</h1>
<p><span id="thm2.1"><strong>Lemma 2.1 (Adjustment Formula)</strong></span>    Let <span class="math inline">\(\mathcal{G}\)</span> be a causal DAG, then <span class="math display">\[p(y \mid \text{do}(z))=\sum_{x_{\text{pa}(z)}} p(x_{\text{pa}(z)}) p(y \mid z, x_{\text{pa}(z)}).\]</span></p>
<p><strong><em>Proof.</em></strong> Let <span class="math inline">\(X_V=(Y, Z, X_{\text{pa}(z)}, X_W)\)</span> where <span class="math inline">\(X_W\)</span> contains any other variables. Then by definition <span class="math display">\[\begin{aligned}
p(y, x_{\text{pa}(z)}, x_W \mid \text{do}(z))&amp;=\prod_{i \in W} p(x_i \mid x_{\text{pa}(i)})p(y \mid x_{\text{pa}(y)}) p(x_{\text{pa}(z)} \mid x_{\text{pa}(\text{pa}(z))})
\\&amp;=\frac{p(y, x_{\text{pa}(z)}, x_W, z)}{p(z \mid x_{\text{pa}(z)})}
\\&amp;=\frac{p(z \mid x_{\text{pa}(z)})p(x_{\text{pa}(z)})p(y, x_W \mid z, x_{\text{pa}(z)})}{p(z \mid x_{\text{pa}(z)})}
\\&amp;=p(x_{\text{pa}(z)})p(y, x_W \mid z, x_{\text{pa}(z)}).
\end{aligned}\]</span></p>
Hence, <span class="math display">\[\begin{aligned}
p(y \mid \text{do}(z))&amp;=\sum_{x_{\text{pa}(z)}, x_W} p(y, x_{\text{pa}(z)}, x_W \mid \text{do}(z))
\\&amp;=\sum_{x_{\text{pa}(z)}} p(x_{\text{pa}(z)})\sum_{x_W}p(y, x_W \mid z, x_{\text{pa}(z)})
\\&amp;=\sum_{x_{\text{pa}(z)}} p(x_{\text{pa}(z)})p(y \mid z, x_{\text{pa}(z)}).
\end{aligned}\]</span>
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><strong>Example 2.1</strong>    </p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            Z((Z)) --> W((W))
T((T)) --> X((X)) --> Y((Y))
Z --> X
W --> Y
          </pre>
<p>According to <a href="#thm2.1">adjustment formula</a>, <span class="math inline">\(\displaystyle p(y \mid \text{do}(x))=\sum_{t, z}p(t, z)p(y \mid x, t, z)\)</span>. Since <span class="math inline">\(T \perp\!\!\!\!\perp Y \mid X, Z\)</span>, then <span class="math display">\[p(y \mid \text{do}(x))=\sum_{t, z}p(t, z)p(y \mid x, z)=\sum_z p(z)p(y \mid x, z).\]</span></p>
<p>Besides, we have <span class="math display">\[\begin{aligned}
p(y \mid \text{do}(x))&amp;=\sum_z p(z)p(y \mid x, z)
\\&amp;=\sum_{z, w} p(z)p(y, w \mid x, z)
\\&amp;=\sum_{z, w} p(z)p(w \mid x, z)p(y \mid w, x, z)
\\&amp;=\sum_{z, w} p(z)p(w \mid z)p(y \mid w, x)
\\&amp;=\sum_{w} p(w)p(y \mid w, x)
\end{aligned}\]</span></p>
<div class="note info">
            <p>The example illustrates that there are often multiple equivalent ways of obtaining the same causal quantity.</p>
          </div>
<h1 id="d-separation">3. d-Separation</h1>
<p><strong>Definition 3.1</strong>    Let <span class="math inline">\(\mathcal{G}\)</span> be a DAG, and <span class="math inline">\(\pi\)</span> be a path in <span class="math inline">\(\mathcal{G}\)</span>. We say that an <em>internal</em> vertex (i.e., not the first and the last vertex on <span class="math inline">\(\pi\)</span>) <span class="math inline">\(v\)</span> is a <strong>collider</strong> if both adjacent edges point to <span class="math inline">\(v\)</span>: <span class="math inline">\(\to v \leftarrow\)</span>. Otherwise, <span class="math inline">\(v\)</span> is a <strong>non-collider</strong>.</p>
<p><strong>Definition 3.2</strong>    Let <span class="math inline">\(\pi\)</span> be a path from <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span>. We say that <span class="math inline">\(\pi\)</span> is <strong>open</strong> conditional on <span class="math inline">\(C \subseteq V-\{a, b\}\)</span> if:</p>
<ul>
<li><p>every collider must be in <span class="math inline">\(\text{an}(C)\)</span>;</p></li>
<li><p>no non-collider can be in <span class="math inline">\(C\)</span>.</p></li>
</ul>
<p>Otherwise, <span class="math inline">\(\pi\)</span> is <strong>blocked</strong> or <strong>closed</strong> given <span class="math inline">\(C\)</span>.</p>
<p><strong>Example 3.1</strong>    </p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            Z((Z)) --> W((W))
T((T)) --> X((X)) --> Y((Y))
Z --> X
W --> Y
          </pre>
<p>We have <span class="math display">\[\begin{aligned}
\pi_1&amp;: T \to X \to Y \quad \text{(Direct causal path)}\\
\pi_2&amp;: T \to X \leftarrow Z \to W \to Y \quad \text{(Backdoor path)}
\end{aligned}\]</span></p>
<p>Given <span class="math inline">\(\varnothing\)</span>, <span class="math inline">\(\pi_1\)</span> is open since <span class="math inline">\(X\)</span> is a non-collider not in <span class="math inline">\(\varnothing\)</span>; <span class="math inline">\(\pi_2\)</span> is blocked since <span class="math inline">\(X\)</span> is a collider not in <span class="math inline">\(\text{an}(\varnothing)\)</span>.</p>
<p>Given <span class="math inline">\(\{X\}\)</span>, <span class="math inline">\(\pi_1\)</span> is blocked since <span class="math inline">\(X\)</span> is a non-collider in <span class="math inline">\(\{X\}\)</span>; <span class="math inline">\(\pi_2\)</span> is open since <span class="math inline">\(X\)</span> is a collider in <span class="math inline">\(\text{an}(\{X\})\)</span>.</p>
<p>Given <span class="math inline">\(\{X, Z\}\)</span>, <span class="math inline">\(\pi_1\)</span> and <span class="math inline">\(\pi_2\)</span> are blocked.</p>
<p><strong>Definition 3.3</strong>    Let <span class="math inline">\(A, B, C\)</span> be disjoint subsets of <span class="math inline">\(V\)</span> in a DAG <span class="math inline">\(\mathcal{G}\)</span>, where <span class="math inline">\(C\)</span> may be empty. We say <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are <strong>d-separated</strong> given <span class="math inline">\(C\)</span>, if all paths from any <span class="math inline">\(a \in A\)</span> to any <span class="math inline">\(b \in B\)</span> are blocked by <span class="math inline">\(C\)</span>, denoted <span class="math inline">\(A \perp_d B \mid C\)</span>.</p>
<p><strong>Theorem 3.1</strong>    Let <span class="math inline">\(\mathcal{G}\)</span> be a DAG with disjoint subsets <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>. Then <span class="math inline">\(A \perp_s B \mid C\ [(\mathcal{G}_{\text{an}(A \cup B \cup C)})^m]\)</span> iff <span class="math inline">\(A\)</span> is d-separated from <span class="math inline">\(B\)</span> by <span class="math inline">\(C\)</span> in <span class="math inline">\(\mathcal{G}\)</span>.</p>
<h1 id="adjustment-set">4. Adjustment Set</h1>
<p><strong>Definition 4.1</strong>    <span class="math inline">\(C\)</span> is an <strong>adjustment set</strong> for <span class="math inline">\((t, y)\)</span> if <span class="math display">\[p(y \mid \text{do}(t))=\sum_{x_C} p(x_C)p(y \mid t, x_C).\]</span></p>
<div class="note info">
            <p><span class="math inline">\(C=\text{pa}(t)\)</span> is an adjustment set.</p>
          </div>
<p><strong>Definition 4.2</strong>    Given a causal effect <span class="math inline">\(T \to Y\)</span>, we define the <strong>causal nodes</strong> <span class="math inline">\(\text{cn}(T \to Y)\)</span> to be nodes on a causal path from <span class="math inline">\(T\)</span> to <span class="math inline">\(Y\)</span>, except for <span class="math inline">\(T\)</span>, i.e., <span class="math display">\[\text{cn}(T \to Y)=\text{an}(Y) \cap \text{de}(T)-\{T\}.\]</span> We define the <strong>forbidden nodes</strong> for <span class="math inline">\(T \to Y\)</span> as consisting of <span class="math inline">\(T\)</span> or any descendants of causal nodes, i.e., <span class="math display">\[\text{forb}(T \to Y)=\text{de}(\text{cn}(T \to Y)) \cup \{T\}.\]</span></p>
<p><strong>Example 4.1</strong>    </p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            Z((Z)) --> W((W))
Z --> X((X))
W --> Y((Y))
T((T)) --> X --> Y --> S((S))
T --> Y
X --> R((R))
          </pre>
<p>By definition <span class="math inline">\(\text{cn}(T \to Y)=\{X, Y\}\)</span> and <span class="math inline">\(\text{forb}(T \to Y)=\{R, S, T, X, Y\}\)</span>.</p>
<p><strong>Definition 4.3</strong>    Given a causal effect <span class="math inline">\(T \to Y\)</span>, we say that <span class="math inline">\(C \subseteq V-\{T, Y\}\)</span> is a <strong>valid adjustment set</strong> if:</p>
<ul>
<li><p><span class="math inline">\(C \cap \text{forb}(T \to Y)=\varnothing\)</span>;</p></li>
<li><p><span class="math inline">\(C\)</span> must block all non-causal path from <span class="math inline">\(T\)</span> to <span class="math inline">\(Y\)</span>.</p></li>
</ul>
<div class="note info">
            <p>We can divide a valid adjustment set <span class="math inline">\(C\)</span> into two components: <span class="math display">\[B=C \cap \text{nd}(T) \quad \text{and} \quad D=C-B=C \cap \text{de}(T).\]</span> We call <span class="math inline">\(B\)</span> the <strong>backdoor adjustment set</strong>.</p>
          </div>
<p><strong>Theorem 4.1</strong>    If <span class="math inline">\(C\)</span> is a valid adjustment set for <span class="math inline">\((T, Y)\)</span>, then so is <span class="math inline">\(B=C \cap \text{nd}(T)\)</span>.</p>
<p><strong><em>Proof.</em></strong> If <span class="math inline">\(C \cap \text{forb}(T \to Y)=\varnothing\)</span>, then <span class="math inline">\(B \cap \text{forb}(T \to Y)=\varnothing\)</span> since <span class="math inline">\(B \subseteq C\)</span>.</p>
<p>Consider path from <span class="math inline">\(T\)</span> to <span class="math inline">\(Y\)</span>. Any path beginning with an edge <span class="math inline">\(T \to \cdots\)</span> is either causal, or will meet a collider.</p>
<ul>
<li><p>Since causal path is open given <span class="math inline">\(C\)</span>, then all non-colliders are outside <span class="math inline">\(C\)</span> and thus are outside <span class="math inline">\(B \subseteq C\)</span>, i.e., causal path is open given <span class="math inline">\(B\)</span>.</p></li>
<li><p>If path meeting a collider is blocked by <span class="math inline">\(C\)</span>, then the collider is not in <span class="math inline">\(\text{an}(C)\)</span>, and thus is not in <span class="math inline">\(\text{an}(B) \subseteq \text{an}(C)\)</span>, i.e., the path meeting a collider is blocked by <span class="math inline">\(B\)</span>.</p></li>
</ul>
<p>Any path beginning with an edge <span class="math inline">\(T \leftarrow \cdots\)</span> is blocked by <span class="math inline">\(C\)</span>.</p>
<ul>
<li><p>If the path is blocked at a collider, then the collider is not in <span class="math inline">\(\text{an}(C)\)</span>, and thus is not in <span class="math inline">\(\text{an}(B) \subseteq \text{an}(C)\)</span> i.e., the path is blocked by <span class="math inline">\(B\)</span>.</p></li>
<li><p>If the path is blocked at a non-collider that is not in <span class="math inline">\(\text{de}(T)\)</span>, then the non-collider is in <span class="math inline">\(B\)</span>, i.e., the path is blocked by <span class="math inline">\(B\)</span>.</p></li>
<li><p>If the path <span class="math inline">\(\pi_1\)</span> is blocked at a non-collider that is in <span class="math inline">\(\text{de}(T)\)</span>, then the non-collider is in <span class="math inline">\(D\)</span> and <span class="math inline">\(\pi_1\)</span> is blocked by <span class="math inline">\(D\)</span>. Consider the path <span class="math inline">\(\pi_2\)</span> from <span class="math inline">\(T\)</span> to <span class="math inline">\(Y\)</span> with <span class="math inline">\(T \to D \to \cdots\)</span>, then there must be a collider on <span class="math inline">\(\pi_2\)</span>, and thus <span class="math inline">\(\pi_1\)</span> is blocked by <span class="math inline">\(B\)</span>.</p></li>
</ul>
Hence <span class="math inline">\(B\)</span> is a valid adjustment set for <span class="math inline">\((T, Y)\)</span>.
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<div class="note info">
            <p>It <span class="math inline">\(C\)</span> is a valid adjustment set for <span class="math inline">\((T, Y)\)</span>, then any superset of <span class="math inline">\(B\)</span> that removes a set closed under taking descendants (any set <span class="math inline">\(B \cup A\)</span> for <span class="math inline">\(A \subseteq D\)</span> with <span class="math inline">\(\text{an}(A) \cap D=A \cap D=A\)</span>) is a valid adjustment set for <span class="math inline">\((T, Y)\)</span>.</p>
          </div>
<p><strong>Theorem 4.2</strong>    For any <span class="math inline">\(d \in C-B\)</span>, either <span class="math inline">\(d \perp_d y \mid (C-\text{de}(d)) \cup \{t\}\)</span> or <span class="math inline">\(d \perp_d t \mid C-\text{de}(d)\)</span>, where <span class="math inline">\(C\)</span> is a valid adjustment set for <span class="math inline">\((t, y)\)</span> and <span class="math inline">\(B=C \cap \text{nd}(t)\)</span>.</p>
<strong><em>Proof.</em></strong> Assume for a contradiction that both statements fail. Consider <span class="math inline">\(A=\text{an}(\{d, y, t\} \cup (C-\text{de}(d)))\)</span>. In <span class="math inline">\((\mathcal{G}_A)^m\)</span>, undirected path from <span class="math inline">\(y\)</span> to <span class="math inline">\(d\)</span> does not intersect <span class="math inline">\((C-\text{de}(d)) \cup \{t\}\)</span>, and undirected path from <span class="math inline">\(t\)</span> to <span class="math inline">\(d\)</span> does not intersect <span class="math inline">\(C-\text{de}(d)\)</span>. We can concatenate these two paths to obtain an open path <span class="math inline">\(\pi\)</span> from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> given <span class="math inline">\(C-\text{de}(d)\)</span>, which is a contradiction.
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><span id="thm4.3"><strong>Lemma 4.3</strong></span>    If <span class="math inline">\(C\)</span> is a valid adjustment set and <span class="math inline">\(B=C \cap \text{nd}(t)\)</span>, then <span class="math display">\[\sum_{x_C} p(x_C)p(y \mid t, x_C)=\sum_{x_B} p(x_B)p(y \mid t, x_B).\]</span></p>
<p><strong><em>Proof.</em></strong> Take <span class="math inline">\(d \in C-B\)</span> s.t. <span class="math inline">\(\text{de}(d) \cap C=\{d\}\)</span>. We know that either <span class="math inline">\(d \perp_d y \mid (C-\{d\}) \cup \{t\}\)</span>, in which case we have <span class="math display">\[\begin{aligned}
\sum_{x_C} p(x_C)p(y \mid t, x_C)&amp;=\sum_{x_{C-\{d\}}, x_d} p(x_{C-\{d\}}, x_d)p(y \mid t, x_{C-\{d\}}, x_d)
\\&amp;=\sum_{x_{C-\{d\}}, x_d} p(x_{C-\{d\}}, x_d)p(y \mid t, x_{C-\{d\}})
\\&amp;=\sum_{x_{C-\{d\}}} p(x_{C-\{d\}})p(y \mid t, x_{C-\{d\}}),
\end{aligned}\]</span></p>
<p>or <span class="math inline">\(d \perp_d t \mid C-\{d\}\)</span>, in which case we have <span class="math display">\[\begin{aligned}
\sum_{x_C} p(x_C)p(y \mid t, x_C)&amp;=\sum_{x_C} p(x_{C-\{d\}})p(x_d \mid x_{C-\{d\}})p(y \mid t, x_C)
\\&amp;=\sum_{x_{C-\{d\}}} p(x_{C-\{d\}}) \sum_{x_d} p(x_d \mid x_{C-\{d\}}, t)p(y \mid t, x_C)
\\&amp;=\sum_{x_{C-\{d\}}} p(x_{C-\{d\}}) \sum_{x_d} p(x_d, y \mid x_{C-\{d\}}, t)
\\&amp;=\sum_{x_{C-\{d\}}} p(x_{C-\{d\}})p(y \mid t, x_{C-\{d\}}).
\end{aligned}\]</span></p>
By iteratively removing such <span class="math inline">\(d\)</span>, the result holds.
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><strong>Theorem 4.3</strong>    Let <span class="math inline">\(C\)</span> be a valid adjustment set for <span class="math inline">\(T \to Y\)</span>, then <span class="math display">\[p(y \mid \text{do}(t))=\sum_{x_C} p(x_C)p(y \mid t, x_C).\]</span></p>
<p><strong><em>Proof.</em></strong>    By <a href="#thm4.3">lemma 4.2</a>, it is sufficient to prove with assumption that <span class="math inline">\(C\)</span> contains no descendants of <span class="math inline">\(t\)</span>. Since <span class="math inline">\(C \cap \text{de}(t) = \varnothing\)</span>, then <span class="math inline">\(t \perp_d C \mid \text{pa}(t)\)</span> by local Markov property.</p>
<p>Suppose there is an open path <span class="math inline">\(\pi\)</span> from some <span class="math inline">\(s \in \text{pa}(t)\)</span> to <span class="math inline">\(y\)</span> given <span class="math inline">\(C \cup \{t\}\)</span>. If <span class="math inline">\(\pi\)</span> passes through <span class="math inline">\(t\)</span>, then <span class="math inline">\(t\)</span> is a collider on the path, and we can shorten it to give an open path from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> that begins <span class="math inline">\(t \leftarrow\)</span>, and thus the path from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> is open given <span class="math inline">\(C\)</span>, which is a contradiction. If <span class="math inline">\(\pi\)</span> is open given <span class="math inline">\(C\)</span>, then the path from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> is open given <span class="math inline">\(C\)</span>, which is a contradiction. If <span class="math inline">\(\pi\)</span> is not open given <span class="math inline">\(C\)</span>, then there exits a collider <span class="math inline">\(r \in \text{an}(t)-\text{an}(C)\)</span>, and there is a directed path from <span class="math inline">\(r\)</span> to <span class="math inline">\(t\)</span> that does not contain any element of <span class="math inline">\(C\)</span>. We concatenate the path from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> and the path is open given <span class="math inline">\(C\)</span>. Hence, we will always obtain an open path from <span class="math inline">\(t\)</span> to <span class="math inline">\(y\)</span> given <span class="math inline">\(C\)</span>, which is a contradiction. Hence, <span class="math inline">\(y \perp_d \text{pa}(t) \mid C \cup \{t\}\)</span>.</p>
Then <span class="math display">\[\begin{aligned}
p(y \mid \text{do}(t))&amp;=\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)})p(y \mid t, x_{\text{pa}(t)})
\\&amp;=\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)}) \sum_{x_C} p(y, x_C \mid t, x_{\text{pa}(t)})
\\&amp;=\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)}) \sum_{x_C} p(y \mid t, x_{\text{pa}(t)}, x_C)p(x_C \mid t, x_{\text{pa}(t)})
\\&amp;=\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)}) \sum_{x_C} p(y \mid t, x_C)p(x_C \mid x_{\text{pa}(t)})
\\&amp;=\sum_{x_C} p(y \mid t, x_C)\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)})p(x_C \mid x_{\text{pa}(t)})
\\&amp;=\sum_{x_C} p(y \mid t, x_C)\sum_{x_{\text{pa}(t)}} p(x_{\text{pa}(t)}, x_C)
\\&amp;=\sum_{x_C} p(y \mid t, x_C)p(x_C).
\end{aligned}\]</span>
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<h1 id="gaussian-causal-model">5. Gaussian Causal Model</h1>
<p>The adjustment formula is a way of estimating causal effect using observational distributions: <span class="math display">\[\mathbb{E}[Y \mid \text{do}(z)]=\sum_{x_C}p(x_C)\mathbb{E}[Y \mid z, x_C].\]</span></p>
<p>For multivariate Gaussian, <span class="math inline">\(\displaystyle \mathbb{E}[Y \mid z, x_C]=\beta_0+\beta_zz+\sum_{c \in C} \alpha_cx_c\)</span>, and thus <span class="math display">\[\begin{aligned}
\mathbb{E}[Y \mid \text{do}(z)]&amp;=\int_{\mathcal{X}_C} p(x_C)\left(\beta_0+\beta_zz+\sum_{c \in C} \alpha_cx_c\right)\text{d}x_C
\\&amp;=\beta_0+\beta_zz+\sum_{c \in C} \alpha_c\mathbb{E}[X_c].
\end{aligned}\]</span></p>
<p>The causal effect for <span class="math inline">\(Z\)</span> on <span class="math inline">\(Y\)</span> is <span class="math inline">\(\beta_z\)</span>.</p>
<h1 id="structural-equation-model">6. Structural Equation Model</h1>
<div class="note info">
            <p>A <strong>structural equation model</strong> is a multivariate Gaussian causal model.</p>
          </div>
<p>Recall that <span class="math inline">\(p\)</span> is multivariate Gaussian and Markov w.r.t. a DAG <span class="math inline">\(\mathcal{G}\)</span> iff <span class="math display">\[X_v=\sum_{p \in \text{pa}(v)} \beta_{vp}X_p+\varepsilon_v\]</span> where <span class="math inline">\(\varepsilon_v \sim \mathcal{N}(0, \sigma_v^2)\)</span> and <span class="math inline">\(\varepsilon_v\)</span>'s are independent.</p>
<p>In matrix form, <span class="math inline">\(X=BX+\varepsilon\)</span> and <span class="math inline">\(X=(I-B)^{-1}\varepsilon\)</span>, where <span class="math inline">\(B\)</span> is lower triangular, <span class="math inline">\(\varepsilon \sim \mathcal{N}_p(0, D)\)</span>, and <span class="math inline">\(D\)</span> is diagonal. We obtain <span class="math display">\[\Sigma=\text{Var}[X]=(I-B)^{-1}\text{Var}[\varepsilon](I-B)^{-T}=(I-B)^{-1}D(I-B)^{-T}.\]</span></p>
<div class="note info">
            <p>We know <span class="math display">\[(B^2)_{ij}=\sum_{k=1}^p \beta_{ik}\beta_{kj}\]</span> and <span class="math inline">\(\beta_{ik}\beta_{kj} \neq 0\)</span> only if <span class="math inline">\(j \to j \to i\)</span> is a directed path in <span class="math inline">\(\mathcal{G}\)</span>. Similarly, <span class="math display">\[(B^3)_{ij}=\sum_{k=1}^p\sum_{l=1}^p \beta_{ik}\beta_{kl}\beta_{lj}\]</span> and <span class="math inline">\(\beta_{ik}\beta_{kl}\beta_{lj} \neq 0\)</span> only if <span class="math inline">\(j \to l \to k \to i\)</span> is a directed path in <span class="math inline">\(\mathcal{G}\)</span>. Since the max path length in <span class="math inline">\(\mathcal{G}\)</span> is <span class="math inline">\(p-1\)</span>, then <span class="math inline">\(B^p=0\)</span>, i.e., <span class="math inline">\(B\)</span> is <strong>nilpotent</strong>.</p>
          </div>
<p>Since <span class="math inline">\(B\)</span> is nilpotent, then <span class="math inline">\((I-B)(I+B+B^2+\cdots+B^{p-1})=I\)</span>, i.e., <span class="math display">\[(I-B)^{-1}=I+B+B^2+\cdots+B^{p-1}.\]</span></p>
<p><strong>Example 6.1</strong>    Consider a DAG</p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            X((X)) --> |&beta;| Z((Z))
X --> |&alpha;| Y((Y))
Y --> |&gamma;| Z
          </pre>
<p>with <span class="math inline">\(X=\varepsilon_x\)</span>, <span class="math inline">\(Y=\alpha X+\varepsilon_y\)</span>, and <span class="math inline">\(Z=\beta X+\gamma Y+\varepsilon_z\)</span> for <span class="math inline">\((\varepsilon_x, \varepsilon_y, \varepsilon_z)^T \sim \mathcal{N}_3(0, I)\)</span>. The matrix form is <span class="math display">\[\begin{bmatrix}
X \\ Y \\ Z
\end{bmatrix}=\begin{bmatrix}
0 &amp; 0 &amp; 0 \\
\alpha &amp; 0 &amp; 0 \\
\beta &amp; \gamma &amp; 0
\end{bmatrix}\begin{bmatrix}
X \\ Y \\ Z
\end{bmatrix}+\begin{bmatrix}
\varepsilon_x \\ \varepsilon_y \\ \varepsilon_z
\end{bmatrix}\]</span> which is equivalent to <span class="math display">\[\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
-\alpha &amp; 1 &amp; 0 \\
-\beta &amp; -\gamma &amp; 1
\end{bmatrix}\begin{bmatrix}
X \\ Y \\ Z
\end{bmatrix}=\begin{bmatrix}
\varepsilon_x \\ \varepsilon_y \\ \varepsilon_z
\end{bmatrix}.\]</span> Therefore, <span class="math display">\[(I-B)^{-1}=\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
-\alpha &amp; 1 &amp; 0 \\
-\beta &amp; -\gamma &amp; 1
\end{bmatrix}^{-1}=\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
\alpha &amp; 1 &amp; 0 \\
\beta+\alpha\gamma &amp; \gamma &amp; 1
\end{bmatrix}\]</span> and <span class="math display">\[\Sigma=(I-B)^{-1}D(I-B)^{-T}=\begin{bmatrix}
1 &amp; \alpha &amp; \beta+\alpha\gamma \\
\alpha &amp; 1+\alpha^2 &amp; \alpha\beta+\alpha^2\gamma+\gamma \\
\beta+\alpha\gamma &amp; \alpha\beta+\alpha^2\gamma+\gamma &amp; 1+\beta^2+\gamma^2+2\alpha\beta\gamma+\alpha^2\gamma^2
\end{bmatrix}.\]</span></p>
<p><strong>Definition 6.1</strong>    Let <span class="math inline">\(\mathcal{G}\)</span> be a DAG with variables <span class="math inline">\(V\)</span>. A <strong>trek</strong> from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> with <strong>source</strong> <span class="math inline">\(k\)</span> is a pair <span class="math inline">\((\pi_l, \pi_r)\)</span> or directed paths, where <span class="math inline">\(\pi_l\)</span> is directed from <span class="math inline">\(k\)</span> to <span class="math inline">\(i\)</span>, and <span class="math inline">\(\pi_r\)</span> is directed from <span class="math inline">\(k\)</span> to <span class="math inline">\(j\)</span>.</p>
<div class="note info">
            <ul><li><p>A vertex may be in both the left and right sides (<span class="math inline">\(\pi_l\)</span> and <span class="math inline">\(\pi_r\)</span>).</p></li><li><p>We may have <span class="math inline">\(i=k\)</span> or <span class="math inline">\(j=k\)</span> or both.</p></li></ul>
          </div>
<p><strong>Example 6.2</strong>    Consider a DAG</p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            X((X)) --> Z((Z))
X --> Y((Y))
Y --> Z
          </pre>
<p>The treks from <span class="math inline">\(Y\)</span> to <span class="math inline">\(Z\)</span> are: <span class="math inline">\(Y \to Z\)</span>, <span class="math inline">\(Y \leftarrow X \to Z\)</span>, and <span class="math inline">\(Y \leftarrow X \to Y \to Z\)</span>.</p>
<p>The treks from <span class="math inline">\(Z\)</span> to <span class="math inline">\(Z\)</span> are: <span class="math inline">\(Z\)</span>, <span class="math inline">\(Z \leftarrow X \to Z\)</span>, <span class="math inline">\(Z \leftarrow Y \to Z\)</span>, <span class="math inline">\(Z \leftarrow X \to Y \to Z\)</span>, <span class="math inline">\(Z \leftarrow Y \leftarrow X \to Z\)</span>, and <span class="math inline">\(Z \leftarrow Y \leftarrow X \to Y \to Z\)</span>.</p>
<p><strong>Definition 6.2</strong>    Let <span class="math inline">\(\tau=(\pi_l, \pi_r)\)</span> be a trek with source <span class="math inline">\(k\)</span>. The <strong>trek covariance</strong> associated with <span class="math inline">\(\tau\)</span> is <span class="math display">\[c(\tau)=d_{kk}\left(\prod_{(i \to j) \in \pi_l} \beta_{ji}\right)\left(\prod_{(i \to j) \in \pi_r} \beta_{ji}\right).\]</span></p>
<div class="note info">
            <p>An empty product is <span class="math inline">\(1\)</span> by convention.</p>
          </div>
<p><strong>Example 6.3</strong>    Consider a DAG</p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            X((X)) --> |&beta;| Z((Z))
X --> |&alpha;| Y((Y))
Y --> |&gamma;| Z
          </pre>
<p>Trek covariances include <span class="math inline">\(c(Z)=1\)</span>, <span class="math inline">\(c(Z \leftarrow X)=\beta\)</span>, <span class="math inline">\(c(Z \leftarrow X \to Y \to Z)=\beta\alpha\gamma\)</span>, and <span class="math inline">\(c(Y \to Z)=\gamma\)</span>.</p>
<p><strong>Theorem 6.1 (Trek Rule)</strong>    Let <span class="math inline">\(\Sigma=(I-B)^{-1}D(I-B)^{-T}\)</span> be a covariance matrix that is Markov w.r.t. a DAG <span class="math inline">\(\mathcal{G}\)</span>. Then <span class="math display">\[\sigma_{ij}=\sum_{\tau \in \mathcal{T}_{ij}} c(\tau)\]</span> where <span class="math inline">\(\mathcal{T}_{ij}\)</span> is the set of treks from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>.</p>
<p><strong><em>Proof.</em></strong> For <span class="math inline">\(p=1\)</span>, <span class="math inline">\(\sigma_{11}=d_{11}\)</span>.</p>
<p>Suppose the trek rule is true for <span class="math inline">\(|V| \leq p-1\)</span>. For <span class="math inline">\(\text{Cov}(X_i, X_j)\)</span>, where <span class="math inline">\(i, j&lt;p\)</span>, we know the trek rule holds by induction hypothesis. Since <span class="math display">\[X_p=\sum_{i \in \text{pa}(p)} \beta_{pi}X_i+\varepsilon_p,\]</span> then for <span class="math inline">\(j&lt;p\)</span>, <span class="math display">\[\begin{aligned}
\text{Cov}(X_p, X_j)&amp;=\sum_{i \in \text{pa}(p)} \beta_{pi}\text{Cov}(X_i, X_j)+\text{Cov}(X_j, \varepsilon_p)
\\&amp;=\sum_{i \in \text{pa}(p)} \beta_{pi}\sum_{\tau \in \mathcal{T}_{ij}} c(\tau)+0.
\end{aligned}\]</span> Since any trek from <span class="math inline">\(p\)</span> to <span class="math inline">\(j\)</span> must consist of the combination of <span class="math inline">\(p \leftarrow i\)</span> for some parent <span class="math inline">\(i\)</span> of <span class="math inline">\(p\)</span>, and a trek from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>, then <span class="math display">\[\text{Cov}(X_p, X_j)=\sum_{i \in \text{pa}(p)} \beta_{pi}\sum_{\tau \in \mathcal{T}_{ij}} c(\tau)=\sum_{\tau \in \mathcal{T}_{pj}} c(\tau).\]</span></p>
Besides, <span class="math display">\[\begin{aligned}
\text{Cov}(X_p, X_p)&amp;=\sum_{i \in \text{pa}(p)} \beta_{pi}\text{Cov}(X_i, X_p)+\text{Cov}(X_p, \varepsilon_p)
\\&amp;=\sum_{i \in \text{pa}(p)} \beta_{pi} \sum_{\tau \in \mathcal{T}_{ip}} c(\tau)+\text{Var}[\varepsilon_p]
\\&amp;=\sum_{\substack{\tau \in \mathcal{T}_{pp} \\ \tau \neq \{p\}}} c(\tau)+d_{pp}
\\&amp;=\sum_{\tau \in \mathcal{T}_{pp}} c(\tau).
\end{aligned}\]</span>
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><strong>Example 6.4</strong>    Consider a DAG</p>
<pre class="mermaid" style="text-align: center;">
            graph LR
            3((3)) --> 2((2)) & 4((4))
1((1)) --> 2 --> 4
          </pre>
<p>For example, <span class="math display">\[\text{Cov}(X_2, X_2)=d_{22}+\beta_{23}^2d_{33}+\beta_{21}^2d_{11}\]</span> and <span class="math display">\[\text{Cov}(X_2, X_4)=\beta_{42}d_{22}+\beta_{23}\beta_{43}d_{33}+\beta_{23}^2\beta_{42}d_{33}+\beta_{21}^2\beta_{42}d_{11}.\]</span></p>
<h1 id="optimal-adjustment-set">7. Optimal Adjustment Set</h1>
<div class="note info">
            <p>The set <span class="math inline">\(O\)</span> is <strong>optimal</strong> in that: <span class="math inline">\(\text{Var}[\widehat{\beta}_{ty \cdot O}]\)</span> is minimal; no subset of <span class="math inline">\(O\)</span> will give the same variance. <span class="math inline">\(\widehat{\beta}_{ty \cdot O}\)</span> is the least squares estimator of regression coefficient that is the effect of <span class="math inline">\(T\)</span> on <span class="math inline">\(Y\)</span> conditional on the variables in <span class="math inline">\(O\)</span>.</p>
          </div>
<p><strong>Proposition 7.1</strong>    Let <span class="math inline">\(\widehat{\beta}_{Cy}=(\widehat{\beta}_{cy \cdot C&#39;})_{c \in C}\)</span>, where <span class="math inline">\(C&#39;=C-\{c\}\)</span>, be the least squares estimator of <span class="math inline">\(\beta_{Cy}\)</span>, where <span class="math inline">\(Y \in \mathbb{R}^n\)</span> and <span class="math inline">\(X_C \in \mathbb{R}^{n \times q}\)</span>, then <span class="math display">\[\sqrt{n}(\widehat{\beta}_{Cy}-\beta_{Cy}) \overset{d}{\to} \mathcal{N}_q(0, \sigma_{yy \cdot C}\Sigma_{CC}^{-1}).\]</span></p>
<p><strong><em>Proof.</em></strong> We know <span class="math display">\[\begin{aligned}
\widehat{\beta}_{Cy}&amp;=(X_C^TX_C)^{-1}X_C^TY
\\&amp;=\left(\frac{1}{n}X_C^TX_C\right)^{-1}\left(\frac{1}{n}X_C^TY\right)
\\&amp;=\left(\frac{1}{n}X_C^TX_C\right)^{-1}\left(\frac{1}{n}X_C^T(X_C\beta_{Cy}+\varepsilon_y)\right)
\\&amp;=\beta_{Cy}+\left(\frac{1}{n}X_C^TX_C\right)^{-1}\left(\frac{1}{n}X_C^T\varepsilon_y\right).
\end{aligned}\]</span></p>
<p>By the law of large numbers, <span class="math inline">\(\displaystyle \frac{1}{n}X_C^TX_C \overset{p}{\to} \Sigma_{CC}\)</span>, then <span class="math display">\[\sqrt{n}(\widehat{\beta}_{Cy}-\beta_{Cy})=\Sigma_{CC}^{-1}\frac{1}{\sqrt{n}}X_C^T\varepsilon_y+\mathcal{O}_p(1).\]</span></p>
It is obvious that <span class="math inline">\(\mathbb{E}[\sqrt{n}(\widehat{\beta}_{Cy}-\beta_{Cy})] \overset{p}{\to} 0\)</span> since <span class="math inline">\(\mathbb{E}[\varepsilon_y]=0\)</span> and <span class="math inline">\(\mathbb{E}[\mathcal{O}_p(1)] \overset{p}{\to} 0\)</span>. Besides, <span class="math display">\[\text{Var}[\sqrt{n}(\widehat{\beta}_{Cy}-\beta_{Cy})] \overset{p}{\to} \Sigma_{CC}^{-1}\Sigma_{CC}(I_n\sigma_{yy \cdot C})\Sigma_{CC}^{-T}=\sigma_{yy \cdot C}\Sigma_{CC}^{-1}.\]</span>
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><span id="thm7.2"><strong>Proposition 7.2</strong></span>    Suppose <span class="math inline">\(C\)</span> and <span class="math inline">\(D\)</span> are valid adjustment sets for <span class="math inline">\(T \to Y\)</span>. Let <span class="math inline">\(C&#39;=C-D\)</span> and <span class="math inline">\(D&#39;=D-C\)</span>. If <span class="math inline">\(Y \perp\!\!\!\!\perp X_{D&#39;} \mid X_C, T\)</span> and <span class="math inline">\(T \perp\!\!\!\!\perp X_{C&#39;} \mid X_D\)</span>, then <span class="math display">\[\frac{\sigma_{yy \cdot tC}}{\sigma_{tt \cdot C}} \leq \frac{\sigma_{yy \cdot tD}}{\sigma_{tt \cdot D}}.\]</span></p>
<strong><em>Proof.</em></strong> Note that <span class="math inline">\(C \cup D=C&#39; \cup D=C \cup D&#39;\)</span>. Since <span class="math inline">\(Y \perp\!\!\!\!\perp X_{D&#39;} \mid X_C, T\)</span>, then <span class="math inline">\(\sigma_{yy \cdot tC}=\sigma_{yy \cdot tCD&#39;}=\sigma_{yy \cdot tC&#39;D}\)</span>. If we remove elements from the conditioning set, the residual variance of <span class="math inline">\(Y\)</span> will only increase or not change, i.e., <span class="math inline">\(\sigma_{yy \cdot tC}=\sigma_{yy \cdot tC&#39;D} \leq \sigma_{yy \cdot tD}\)</span>. Since <span class="math inline">\(T \perp\!\!\!\!\perp X_{C&#39;} \mid X_D\)</span>, then <span class="math inline">\(\sigma_{tt \cdot D}=\sigma_{tt \cdot C&#39;D}=\sigma_{tt \cdot CD&#39;} \leq \sigma_{tt \cdot C}\)</span>. Hence, <span class="math display">\[\frac{\sigma_{yy \cdot tC}}{\sigma_{tt \cdot C}} \leq \frac{\sigma_{yy \cdot tD}}{\sigma_{tt \cdot D}}.\]</span>
<p align="right">
<span class="math inline">\(\square\)</span>
</p>
<p><strong>Definition 7.1</strong>    Given a causal graph <span class="math inline">\(\mathcal{G}\)</span> and a distribution that is Markov w.r.t. <span class="math inline">\(\mathcal{G}\)</span>, the <strong>optimal adjustment set</strong> is <span class="math display">\[O(T \to Y)=\text{pa}(\text{cn}(T \to Y))-(\text{cn}(T \to Y) \cup \{T\}).\]</span></p>
<p><strong>Example 7.1</strong>    Consider the causal graph:</p>
<p><img data-src="/images/Causal_Inference_1.png"></p>
<p>Since <span class="math inline">\(\text{cn}(T \to Y)=\text{an}(Y) \cap \text{de}(T)-\{T\}=\{M, Y\}\)</span>, then <span class="math inline">\(\text{pa}(\text{cn}(T \to Y))=\{T, L, M, X, S\}\)</span>, and thus <span class="math inline">\(O(T \to Y)=\{T, L, M, X, S\}-\{M, Y, T\}=\{X, S, L\}\)</span>. Hence, we choose to block <span class="math inline">\(X\)</span>, and adjust <span class="math inline">\(S\)</span> and <span class="math inline">\(L\)</span>.</p>
<p><strong>Theorem 7.3</strong>    Let <span class="math inline">\(\mathcal{G}\)</span> be a causal DAG containing variables <span class="math inline">\(T\)</span> and <span class="math inline">\(Y\)</span>. Then the set <span class="math inline">\(O(T \to Y)\)</span> is a valid adjustment set, and the asymptotic variance of <span class="math inline">\(\widehat{\beta}_{ty \cdot O}\)</span> is minimal over all valid adjustment sets.</p>
<p><strong><em>Proof.</em></strong> <span class="math inline">\(O\)</span> contains no descendants of <span class="math inline">\(T\)</span>, and any non-causal path from <span class="math inline">\(T\)</span> to <span class="math inline">\(Y\)</span> is blocked since any such path will have a conditioned non-collider as the node immediately before it meets <span class="math inline">\(\text{cn}(T \to Y)\)</span>. Hence <span class="math inline">\(O\)</span> is a valid adjustment set.</p>
<p>Suppose <span class="math inline">\(Z\)</span> is a valid adjustment set, <span class="math inline">\(O&#39;=O-Z\)</span>, and <span class="math inline">\(Z&#39;=Z-O\)</span>. Since <span class="math inline">\((Z \cup O) \cap \text{forb}(T \to Y)=\varnothing\)</span>, then any path (from <span class="math inline">\(Y\)</span> to vertex in <span class="math inline">\(Z&#39;\)</span>) that descends at any point from a node in <span class="math inline">\(\text{cn}(T \to Y)\)</span> are blocked. Any path (from <span class="math inline">\(Y\)</span> to vertex in <span class="math inline">\(Z&#39;\)</span>) that does not descend from <span class="math inline">\(\text{cn}(T \to Y)\)</span> must meet a parent of <span class="math inline">\(\text{cn}(T \to Y)\)</span>, i.e., either <span class="math inline">\(T\)</span> or vertex in <span class="math inline">\(O\)</span>, which is a non-collider on the path, and thus the path is blocked. Hence, <span class="math inline">\(Y \perp_d Z&#39; \mid O \cup \{T\}\)</span>.</p>
<p>If there is an open path from <span class="math inline">\(T\)</span> to <span class="math inline">\(o \in O&#39;\)</span>, then we can concatenate with a directed causal path to <span class="math inline">\(Y\)</span> through <span class="math inline">\(\text{cn}(T \to Y)\)</span>, and obtain that <span class="math inline">\(Z\)</span> is not a valid adjustment set, which is a contradiction. Hence, <span class="math inline">\(T \perp_d O&#39; \mid Z\)</span>.</p>
Therefore, by <a href="#thm7.2">proposition 7.2</a>, <span class="math inline">\(O(T \to Y)\)</span> has minimal variance.
<p align="right">
<span class="math inline">\(\square\)</span>
</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Causal-Inference/" rel="tag"><i class="fa fa-tag"></i> Causal Inference</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Compute_Science/PyTorch/Transformer_in_PyTorch" rel="prev" title="Transformer in PyTorch">
      <i class="fa fa-chevron-left"></i> Transformer in PyTorch
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#causal-inference"><span class="nav-text">1. Causal Inference</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#causal-dag"><span class="nav-text">2. Causal DAG</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#d-separation"><span class="nav-text">3. d-Separation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#adjustment-set"><span class="nav-text">4. Adjustment Set</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#gaussian-causal-model"><span class="nav-text">5. Gaussian Causal Model</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#structural-equation-model"><span class="nav-text">6. Structural Equation Model</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#optimal-adjustment-set"><span class="nav-text">7. Optimal Adjustment Set</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Tianyang Li"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Tianyang Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/litianyang0211" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;litianyang0211" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:tianyang.li@linacre.ox.ac.uk" title="Email → mailto:tianyang.li@linacre.ox.ac.uk" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/derek0211" title="Facebook → https:&#x2F;&#x2F;www.facebook.com&#x2F;derek0211" rel="noopener" target="_blank"><i class="fab fa-facebook fa-fw"></i></a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class=""></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tianyang Li</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'default',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
